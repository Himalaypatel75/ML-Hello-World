# ML-Hello-World
Types of algorithm used
- K-nearest neighbours - model (it will find nearest one)
- Naive Bayes ( it is working on probability)
- 


There are numerous machine learning algorithms, each designed to solve different types of problems and scenarios. The popularity of an algorithm often depends on the specific use case, the nature of the data, and the problem's requirements. Here is a list of some popular machine learning algorithms:

1. **Linear Regression:** Used for predicting a continuous outcome based on one or more predictor features.

2. **Logistic Regression:** Used for binary classification problems, predicting the probability that an instance belongs to a particular class.

3. **Decision Trees:** Tree-like models that make decisions based on feature values at different nodes.

4. **Random Forest:** An ensemble learning method that builds multiple decision trees and merges their predictions.

5. **Support Vector Machines (SVM):** Used for classification and regression tasks, aiming to find a hyperplane that best separates classes.

6. **K-Nearest Neighbors (KNN):** Classifies instances based on the majority class of their k-nearest neighbors in feature space.

7. **K-Means Clustering:** Unsupervised learning algorithm for partitioning data into k clusters based on similarity.

8. **Principal Component Analysis (PCA):** Dimensionality reduction technique used to transform data into a lower-dimensional space.

9. **Naive Bayes:** Probabilistic algorithm based on Bayes' theorem for classification tasks.

10. **Gradient Boosting Machines (e.g., XGBoost, LightGBM):** Ensemble learning method that builds a series of weak learners to create a strong learner.

11. **Neural Networks (Deep Learning):** Multilayered artificial neural networks used for complex tasks such as image recognition and natural language processing.

12. **Recurrent Neural Networks (RNN):** Neural networks designed for sequential data, often used in natural language processing and time series analysis.

13. **Long Short-Term Memory (LSTM):** A type of RNN designed to address the vanishing gradient problem, commonly used in sequential data tasks.

14. **Convolutional Neural Networks (CNN):** Deep learning models designed for processing grid-like data, often used in image and video analysis.

15. **Association Rule Learning (e.g., Apriori):** Used for discovering interesting relationships or associations between variables in large datasets.

16. **Reinforcement Learning:** Learning paradigm where an agent learns to make decisions by interacting with an environment to maximize a cumulative reward.

17. **Gaussian Mixture Models (GMM):** A probabilistic model that represents a mixture of Gaussian distributions, often used in clustering.

18. **Word Embeddings (e.g., Word2Vec, GloVe):** Techniques for representing words as vectors in a continuous vector space, commonly used in natural language processing tasks.

These are just a few examples, and the field of machine learning is dynamic, with new algorithms and variations continually emerging. The choice of algorithm depends on the specific requirements of the task at hand and the characteristics of the data being used.
